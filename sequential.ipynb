{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "from pprint import pprint\n",
    "import string\n",
    "import re\n",
    "from keras.backend import clear_session\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, CuDNNLSTM, Input, Embedding, TimeDistributed, Flatten, Dropout, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading movie lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1044': 'they do to',\n",
      " 'L1045': 'they do not',\n",
      " 'L869': 'like my fear of wearing pastels',\n",
      " 'L870': 'im kidding you know how sometimes you just become this persona and '\n",
      "         'you dont know how to quit',\n",
      " 'L871': 'no',\n",
      " 'L872': 'okay youre gonna need to learn how to lie',\n",
      " 'L924': 'wow',\n",
      " 'L925': 'lets go',\n",
      " 'L984': 'she okay',\n",
      " 'L985': 'i hope so'}\n",
      "\n",
      "[['L194', 'L195', 'L196', 'L197'],\n",
      " ['L198', 'L199'],\n",
      " ['L200', 'L201', 'L202', 'L203'],\n",
      " ['L204', 'L205', 'L206'],\n",
      " ['L207', 'L208'],\n",
      " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
      " ['L276', 'L277'],\n",
      " ['L280', 'L281'],\n",
      " ['L363', 'L364'],\n",
      " ['L365', 'L366']]\n"
     ]
    }
   ],
   "source": [
    "table = str.maketrans('', '', string.punctuation)\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def clean_sentence(line):\n",
    "    line = line.strip().replace('--', '').replace(\"  \", \" \").replace('\"', \"\")\n",
    "    line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "    line = line.decode('UTF-8')\n",
    "    # tokenize on white space\n",
    "    line = line.split()\n",
    "    # convert to lowercase\n",
    "    line = [word.lower() for word in line]\n",
    "    # remove punctuation from each token\n",
    "    line = [word.translate(table) for word in line]\n",
    "    # remove non-printable chars form each token\n",
    "    line = [re_print.sub('', w) for w in line]\n",
    "    # remove tokens with numbers in them\n",
    "    line = [word for word in line if word.isalpha()]\n",
    "    return ' '.join(line)\n",
    "\n",
    "with open('./cornell-movie-dialogs-corpus/movie_lines.txt', 'r', errors='ignore') as f:\n",
    "    lines_as_list = [row.strip() for row in f.readlines()]\n",
    "\n",
    "\n",
    "lines = {}\n",
    "for line in lines_as_list:\n",
    "    lines[\n",
    "        line.split('+++$+++')[0].strip()\n",
    "    ] = clean_sentence(line.split('+++$+++')[-1])  # clean sentences\n",
    "\n",
    "del lines_as_list\n",
    "\n",
    "with open('./cornell-movie-dialogs-corpus/movie_conversations.txt', 'r', errors='ignore') as f:\n",
    "    conversations = [row.strip() for row in f.readlines()]\n",
    "\n",
    "# only take id's and convert list as string to list as list\n",
    "conversations = [\n",
    "    conversation.split('+++$+++')[-1].strip().replace('[', '').replace(']', '').replace(\"'\", '').replace(\" \", '').split(',') \n",
    "    for conversation in conversations\n",
    "]\n",
    "\n",
    "pprint({k: lines[k] for k in list(lines)[:10]})\n",
    "print()\n",
    "pprint(conversations[:10])\n",
    "\n",
    "assert len([conversation for conversation in conversations if len(conversation) <=1]) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map keys to line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yeah', 'what do you think'],\n",
      " ['two legs nice rack',\n",
      "  'yeah whatever i want you to go out with her',\n",
      "  'sure sparky ill get right on it',\n",
      "  'you just said',\n",
      "  'you need money to take a girl out',\n",
      "  'but youd go out with her if you had the cake'],\n",
      " ['you got it verona i pick up the tab you do the honors',\n",
      "  'youre gonna pay me to take out some girl',\n",
      "  'i cant date her sister until that one gets a boyfriend and thats the catch '\n",
      "  'she doesnt want a boyfriend',\n",
      "  'how much'],\n",
      " ['i cant take a girl like that out on twenty bucks', 'fine thirty'],\n",
      " ['take it or leave it this isnt a negotiation',\n",
      "  'fifty and youve got your man'],\n",
      " ['when i shell out fifty i expect results',\n",
      "  'im on it',\n",
      "  'watching the bitch trash my car doesnt count as a date',\n",
      "  'i got her under control she just acts crazed in public to keep up the '\n",
      "  'image'],\n",
      " ['i just upped my price',\n",
      "  'what',\n",
      "  'a hundred bucks a date',\n",
      "  'forget it',\n",
      "  'forget her sister then'],\n",
      " ['its about time', 'a deals a deal'],\n",
      " ['howd you do it', 'do what', 'get her to act like a human'],\n",
      " ['i dont know dorsey the limothe flowers another hundred for the tux',\n",
      "  'enough with the barbie n ken shit i know']]\n"
     ]
    }
   ],
   "source": [
    "conversations_with_lines = []\n",
    "for conversation in conversations:\n",
    "    conversations_with_lines.append([lines[key] for key in conversation])\n",
    "    \n",
    "pprint(conversations_with_lines[100:110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair those things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again',\n",
      "       'well i thought wed start with pronunciation if thats okay with you'],\n",
      "      dtype='<U2857')\n",
      "array(['well i thought wed start with pronunciation if thats okay with you',\n",
      "       'not the hacking and gagging and spitting part please'],\n",
      "      dtype='<U2857')\n",
      "array(['not the hacking and gagging and spitting part please',\n",
      "       'okay then how bout we try out some french cuisine saturday night'],\n",
      "      dtype='<U2857')\n",
      "array(['youre asking me out thats so cute whats your name again',\n",
      "       'forget it'], dtype='<U2857')\n",
      "array(['no no its my fault we didnt have a proper introduction',\n",
      "       'cameron'], dtype='<U2857')\n",
      "array(['cameron',\n",
      "       'the thing is cameron im at the mercy of a particularly hideous breed of loser my sister i cant date until she does'],\n",
      "      dtype='<U2857')\n",
      "array(['the thing is cameron im at the mercy of a particularly hideous breed of loser my sister i cant date until she does',\n",
      "       'seems like she could get a date easy enough'], dtype='<U2857')\n",
      "array(['why',\n",
      "       'unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something'],\n",
      "      dtype='<U2857')\n",
      "array(['unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
      "       'thats a shame'], dtype='<U2857')\n",
      "array(['gosh if only we could find kat a boyfriend',\n",
      "       'let me see what i can do'], dtype='<U2857')\n"
     ]
    }
   ],
   "source": [
    "def pair_it(my_list):\n",
    "    pairs = []\n",
    "    for i in range(len(my_list) -1):\n",
    "        pairs.append([my_list[i], my_list[i + 1]])\n",
    "    return pairs\n",
    "\n",
    "paired_conversations_agg = [\n",
    "    pair_it(conversation) for conversation in conversations_with_lines\n",
    "]\n",
    "conversations_pairs = np.array([item for sublist in paired_conversations_agg for item in sublist])\n",
    "for i in range(10):\n",
    "    pprint(conversations_pairs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.0.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"2a745daf-cba4-4820-a657-cfdbeb5e7ee1\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"feb6bedb-6dba-4ad7-972e-b9a6ddd79a8c\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1022\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1035\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1003\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1039\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1033\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"Selection\"},{\"attributes\":{\"formatter\":{\"id\":\"1039\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1034\",\"type\":\"Quad\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1033\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1034\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1036\",\"type\":\"CDSView\"}},\"id\":\"1035\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"}},\"id\":\"1036\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"PanTool\"},{\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"SaveTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"text\":\"Conversation length distribution\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"AAAAAAAAAAB7FK5H4Xo9QHsUrkfhek1AXI/C9SgcVkB7FK5H4XpdQM3MzMzMbGJAXI/C9SgcZkDsUbgehctpQHsUrkfhem1AhetRuB6VcEDNzMzMzGxyQBWuR+F6RHRAXI/C9SgcdkCkcD0K1/N3QOxRuB6Fy3lAMzMzMzOje0B7FK5H4Xp9QMP1KFyPUn9AhetRuB6VgEApXI/C9YCBQM3MzMzMbIJAcT0K16NYg0AVrkfhekSEQLgehetRMIVAXI/C9SgchkAAAAAAAAiHQKRwPQrX84dASOF6FK7fiEDsUbgehcuJQI/C9Shct4pAMzMzMzOji0DXo3A9Co+MQHsUrkfheo1AH4XrUbhmjkDD9Shcj1KPQDMzMzMzH5BAhetRuB6VkEDXo3A9CguRQClcj8L1gJFAexSuR+H2kUDNzMzMzGySQB+F61G44pJAcT0K16NYk0DD9Shcj86TQBWuR+F6RJRAZmZmZma6lEC4HoXrUTCVQArXo3A9ppVAXI/C9SgclkCuR+F6FJKWQAAAAAAACJdAUrgehet9l0CkcD0K1/OXQPYoXI/CaZhASOF6FK7fmECamZmZmVWZQOxRuB6Fy5lAPgrXo3BBmkCPwvUoXLeaQOF6FK5HLZtAMzMzMzOjm0CF61G4HhmcQNejcD0Kj5xAKVyPwvUEnUB7FK5H4XqdQM3MzMzM8J1AH4XrUbhmnkBxPQrXo9yeQMP1KFyPUp9AFa5H4XrIn0AzMzMzMx+gQFyPwvUoWqBAhetRuB6VoECuR+F6FNCgQNejcD0KC6FAAAAAAABGoUApXI/C9YChQFK4HoXru6FAexSuR+H2oUCkcD0K1zGiQM3MzMzMbKJA9ihcj8KnokAfhetRuOKiQEjhehSuHaNAcT0K16NYo0CamZmZmZOjQMP1KFyPzqNA7FG4HoUJpEAVrkfhekSkQD4K16Nwf6RAZmZmZma6pECPwvUoXPWkQLgehetRMKVA4XoUrkdrpUAK16NwPaalQDMzMzMz4aVAXI/C9SgcpkCF61G4HlemQK5H4XoUkqZA16NwPQrNpkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"exSuR+F6PUB7FK5H4XpNQFyPwvUoHFZAexSuR+F6XUDNzMzMzGxiQFyPwvUoHGZA7FG4HoXLaUB7FK5H4XptQIXrUbgelXBAzczMzMxsckAVrkfhekR0QFyPwvUoHHZApHA9Ctfzd0DsUbgehct5QDMzMzMzo3tAexSuR+F6fUDD9Shcj1J/QIXrUbgelYBAKVyPwvWAgUDNzMzMzGyCQHE9CtejWINAFa5H4XpEhEC4HoXrUTCFQFyPwvUoHIZAAAAAAAAIh0CkcD0K1/OHQEjhehSu34hA7FG4HoXLiUCPwvUoXLeKQDMzMzMzo4tA16NwPQqPjEB7FK5H4XqNQB+F61G4Zo5Aw/UoXI9Sj0AzMzMzMx+QQIXrUbgelZBA16NwPQoLkUApXI/C9YCRQHsUrkfh9pFAzczMzMxskkAfhetRuOKSQHE9CtejWJNAw/UoXI/Ok0AVrkfhekSUQGZmZmZmupRAuB6F61EwlUAK16NwPaaVQFyPwvUoHJZArkfhehSSlkAAAAAAAAiXQFK4HoXrfZdApHA9Ctfzl0D2KFyPwmmYQEjhehSu35hAmpmZmZlVmUDsUbgehcuZQD4K16NwQZpAj8L1KFy3mkDhehSuRy2bQDMzMzMzo5tAhetRuB4ZnEDXo3A9Co+cQClcj8L1BJ1AexSuR+F6nUDNzMzMzPCdQB+F61G4Zp5AcT0K16PcnkDD9Shcj1KfQBWuR+F6yJ9AMzMzMzMfoEBcj8L1KFqgQIXrUbgelaBArkfhehTQoEDXo3A9CguhQAAAAAAARqFAKVyPwvWAoUBSuB6F67uhQHsUrkfh9qFApHA9CtcxokDNzMzMzGyiQPYoXI/Cp6JAH4XrUbjiokBI4XoUrh2jQHE9CtejWKNAmpmZmZmTo0DD9Shcj86jQOxRuB6FCaRAFa5H4XpEpEA+CtejcH+kQGZmZmZmuqRAj8L1KFz1pEC4HoXrUTClQOF6FK5Ha6VACtejcD2mpUAzMzMzM+GlQFyPwvUoHKZAhetRuB5XpkCuR+F6FJKmQNejcD0KzaZAAAAAAAAIp0A=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"C0s9afd6bT/F9q7jNE+BP8bZ/b1+MH0/gh8m8mXDcz8Zyc3FUTVrPyBUUAWXY2E/lEPpjoCqVz+tux8HFRROP4SR677SckQ/Sec3QjJBOz+us0nukB4zP6GV4pAL3So/WHCjWWZbIj/rsPrp1swZPzeiG7f/bRY/anc+d+ZICz/v7WWNNx4JP8tJW/4z2gA/ZHDgFQau+T4UUJbv/UvyPgp9VviZkew+LWwOdX+36D6ISn5uSgPhPvdnPNT4wNc+6lmAETiL1D7qWYAROIvUPgN2+Ja59so+WGIkU0V41j7ATlAP0fnBPidlsBOfHMc+Dkk4jh2xwD6hexAYbT+8Pg5JOI4dscA+oXsQGG0/vD7AexAYbT+8PupZgBE4i7Q+6lmAETiLlD7qWYAROIukPmRw4BUGrqk+6lmAETiLlD7fhkAa1NCePupZgBE4i4Q+34ZAGtTQnj4AAAAAAAAAACGHQBrU0J4+AAAAAAAAAAAAAAAAAAAAAOpZgBE4i5Q+6lmAETiLhD7qWYAROIuUPupZgBE4i5Q+6lmAETiLhD7qWYAROIuEPgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqWYAROIuEPgAAAAAAAAAA6lmAETiLhD7qWYAROIuEPgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqWYAROIuEPgAAAAAAAAAA6lmAETiLhD4=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"1042\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1043\",\"type\":\"UnionRenderers\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.3.0\"}};\n",
       "  var render_items = [{\"docid\":\"feb6bedb-6dba-4ad7-972e-b9a6ddd79a8c\",\"roots\":{\"1002\":\"2a745daf-cba4-4820-a657-cfdbeb5e7ee1\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest conversation: \n",
      "['the food and drug administration said wednesday female deodorant sprays may cause such harmful reactions as blisters burns and rashes although the fda judges that the reported reactions are not sufficient to justify removal of these products from the market they are sufficient to warrant the proposed mandatory label warnings'\n",
      " 'shit o dear thats enough to make me asthmatic the nerve of those twits what do they know about female odor dont interrupt heres my concept my ranch out west its a beauty ranch oh its got a few head of cattle for atmosphere and tax purposes but its a beauty ranch a place where unhappy women divorcees and widows mainly can go to lose weight remove wrinkles change their hair styles and pretty themselves up for the next disappointment my ranch is named the rubber rose after the rubber rose douche bag my own invention and bless its little red bladder the most popular douche bag in the world so get this its on the migratory flight path of the whooping cranes the last flock of wild whooping cranes left in existence well these cranes stop off at my little pond siwash lake its called twice a year autumn and spring and spend a few days each time resting up eating doing whatever whooping cranes do ive never seen them understand but i hear theyre magnificent very big specimens i mean huge mothers and white as snow to coin a phrase except for black tips on their wings and tail feathers and bright red heads now whooping cranes in case you didnt know it are noted for their mating dance its just the wildest show in nature its probably the reason why birdwatching used to be so popular with old maids and deacons picture these rare beautiful gigantic birds in full dance leaping six feet off the mud arching their backs flapping their wings strutting low to the ground dears its overwhelming and picture the birds doing their sex dance on tv right there on the home screen creations most elaborate sex ritual yet clean and pure enough to suit the pope with lovely sissy hankshaw in the foreground in a white gown red hood attached and big feathery sleeves trimmed in black in a very subdued imitation of the female whooping crane she dancewalks over to a large nest in which there sits a can of yoni yum and a can of dew offcamera a string quartet is playing debussy a sensuous voice is reading a few poetic lines about courtship and love are you starting to get it doesnt it make the hair on your neck stand up and applaud my very goodness gracious grandiose lyrical erotic and girl scout oriented you cant top it ive hired a crew of experts from walt disney studios the best wildlife cinematographers around youre my eternal favorite princess grace herself couldnt be better not even if she had your personality which she doesnt anyway dear im out of photography now and into water colors ah how circuitous conversation is were back at the beginning the exact man ive wanted you to meet is my artist the watercolorist']\n",
      "\n",
      "longest conversation lenght: 2948\n",
      "filetered 1009 conversations\n"
     ]
    }
   ],
   "source": [
    "output_notebook()\n",
    "hist, edges = np.histogram([len(question) + len(answer) for question, answer in conversations_pairs], density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Conversation length distribution\")\n",
    "\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)\n",
    "longest_converastion = conversations_pairs[np.array([len(question) + len(answer) for question, answer in conversations_pairs]).argmax()]\n",
    "print(\"longest conversation: \\n{}\".format(longest_converastion))\n",
    "print(\"\\nlongest conversation lenght: {}\".format(len(longest_converastion[0]) + len(longest_converastion[1])))\n",
    "max_conversation_lenght = 500  # maximum alowed converastion lenght in characters\n",
    "# clensed_conversations = np.where((len(conversations_pairs[:,0]) + len(conversations_pairs[:,1])) < max_conversation_lenght)\n",
    "clensed_conversations = np.array([conversation_pair for conversation_pair in conversations_pairs if len(conversation_pair[0]) + len(conversation_pair[1]) < max_conversation_lenght])\n",
    "print(\"filetered {} conversations\".format(len(conversations_pairs) - len(clensed_conversations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shity magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 27\n",
      "Max sequence length for inputs: 496\n",
      "Max sequence length for outputs: 494\n",
      "trainX (176485, 496) | trainY (176485, 496, 27) | testX (44122, 496) | testY (44122, 496, 27)\n"
     ]
    }
   ],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for input_text, target_text in clensed_conversations:\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_input_tokens = len(input_characters)\n",
    "num_target_tokens = len(target_characters)\n",
    "max_input_seq_length = max([len(input_text) for input_text, target_text in clensed_conversations])\n",
    "max_target_seq_length = max([len(target_text) for input_text, target_text in clensed_conversations])\n",
    "max_sentence_lenght = max(max_input_seq_length, max_target_seq_length)\n",
    "\n",
    "print('Number of unique input tokens:', num_input_tokens)\n",
    "print('Number of unique output tokens:', num_target_tokens)\n",
    "print('Max sequence length for inputs:', max_input_seq_length)\n",
    "print('Max sequence length for outputs:', max_target_seq_length)\n",
    "\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "split_index = int(len(clensed_conversations) * .8)\n",
    "pre_trainX = clensed_conversations[:split_index, 0]\n",
    "pre_trainY = clensed_conversations[:split_index, 1]\n",
    "pre_testX = clensed_conversations[split_index:, 0]\n",
    "pre_testY = clensed_conversations[split_index:, 1]\n",
    "\n",
    "trainX = np.zeros((len(pre_trainX), max_sentence_lenght), dtype='float32')\n",
    "trainY = np.zeros((len(pre_trainY), max_sentence_lenght, num_target_tokens), dtype='float32')\n",
    "testX = np.zeros((len(pre_testX), max_sentence_lenght), dtype='float32')\n",
    "testY = np.zeros((len(pre_testY), max_sentence_lenght, num_target_tokens), dtype='float32')\n",
    "\n",
    "print(\"trainX {} | trainY {} | testX {} | testY {}\".format(trainX.shape, trainY.shape, testX.shape, testY.shape))\n",
    "\n",
    "for i, (input_text) in enumerate(pre_trainX):\n",
    "    for t, char in enumerate(input_text):\n",
    "        trainX[i, t] = target_token_index[char]\n",
    "\n",
    "for i, (target_text) in enumerate(pre_trainY):\n",
    "    for t, char in enumerate(target_text):\n",
    "        trainY[i, t, target_token_index[char]] = 1.\n",
    "\n",
    "for i, (input_text) in enumerate(pre_testX):\n",
    "    for t, char in enumerate(input_text):\n",
    "        testX[i, t] = target_token_index[char]\n",
    "\n",
    "for i, (target_text) in enumerate(pre_testY):\n",
    "    for t, char in enumerate(target_text):\n",
    "        testY[i, t, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 496, 256)          6912      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 496, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 496, 256)          525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 496, 27)           6939      \n",
      "=================================================================\n",
      "Total params: 1,064,475\n",
      "Trainable params: 1,064,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "n_units=256\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_input_tokens, n_units, input_length=max_sentence_lenght, mask_zero=True))\n",
    "model.add(LSTM(n_units))  # CuDNNLSTM\n",
    "model.add(RepeatVector(max_sentence_lenght))\n",
    "model.add(LSTM(n_units, return_sequences=True))  # CuDNNLSTM\n",
    "model.add(TimeDistributed(Dense(num_target_tokens, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "filename = 'mount-this/model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
