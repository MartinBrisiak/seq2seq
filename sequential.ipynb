{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "from pprint import pprint\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# import plaidml.keras.backend as K\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, CuDNNLSTM, Input, Embedding, TimeDistributed, Flatten, Dropout, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading movie lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1044': 'they do to',\n",
      " 'L1045': 'they do not',\n",
      " 'L869': 'like my fear of wearing pastels',\n",
      " 'L870': 'im kidding you know how sometimes you just become this persona and '\n",
      "         'you dont know how to quit',\n",
      " 'L871': 'no',\n",
      " 'L872': 'okay youre gonna need to learn how to lie',\n",
      " 'L924': 'wow',\n",
      " 'L925': 'lets go',\n",
      " 'L984': 'she okay',\n",
      " 'L985': 'i hope so'}\n",
      "\n",
      "[['L194', 'L195', 'L196', 'L197'],\n",
      " ['L198', 'L199'],\n",
      " ['L200', 'L201', 'L202', 'L203'],\n",
      " ['L204', 'L205', 'L206'],\n",
      " ['L207', 'L208'],\n",
      " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
      " ['L276', 'L277'],\n",
      " ['L280', 'L281'],\n",
      " ['L363', 'L364'],\n",
      " ['L365', 'L366']]\n"
     ]
    }
   ],
   "source": [
    "table = str.maketrans('', '', string.punctuation)\n",
    "# prepare regex for char filtering\n",
    "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "# prepare translation table for removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def clean_sentence(line):\n",
    "    line = line.strip().replace('--', '').replace(\"  \", \" \").replace('\"', \"\")\n",
    "    line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "    line = line.decode('UTF-8')\n",
    "    # tokenize on white space\n",
    "    line = line.split()\n",
    "    # convert to lowercase\n",
    "    line = [word.lower() for word in line]\n",
    "    # remove punctuation from each token\n",
    "    line = [word.translate(table) for word in line]\n",
    "    # remove non-printable chars form each token\n",
    "    line = [re_print.sub('', w) for w in line]\n",
    "    # remove tokens with numbers in them\n",
    "    line = [word for word in line if word.isalpha()]\n",
    "    return ' '.join(line)\n",
    "\n",
    "with open('./cornell-movie-dialogs-corpus/movie_lines.txt', 'r', errors='ignore') as f:\n",
    "    lines_as_list = [row.strip() for row in f.readlines()]\n",
    "\n",
    "\n",
    "lines = {}\n",
    "for line in lines_as_list:\n",
    "    lines[\n",
    "        line.split('+++$+++')[0].strip()\n",
    "    ] = clean_sentence(line.split('+++$+++')[-1])  # clean sentences\n",
    "\n",
    "del lines_as_list\n",
    "\n",
    "with open('./cornell-movie-dialogs-corpus/movie_conversations.txt', 'r', errors='ignore') as f:\n",
    "    conversations = [row.strip() for row in f.readlines()]\n",
    "\n",
    "# only take id's and convert list as string to list as list\n",
    "conversations = [\n",
    "    conversation.split('+++$+++')[-1].strip().replace('[', '').replace(']', '').replace(\"'\", '').replace(\" \", '').split(',') \n",
    "    for conversation in conversations\n",
    "]\n",
    "\n",
    "pprint({k: lines[k] for k in list(lines)[:10]})\n",
    "print()\n",
    "pprint(conversations[:10])\n",
    "\n",
    "assert len([conversation for conversation in conversations if len(conversation) <=1]) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map keys to line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yeah', 'what do you think'],\n",
      " ['two legs nice rack',\n",
      "  'yeah whatever i want you to go out with her',\n",
      "  'sure sparky ill get right on it',\n",
      "  'you just said',\n",
      "  'you need money to take a girl out',\n",
      "  'but youd go out with her if you had the cake'],\n",
      " ['you got it verona i pick up the tab you do the honors',\n",
      "  'youre gonna pay me to take out some girl',\n",
      "  'i cant date her sister until that one gets a boyfriend and thats the catch '\n",
      "  'she doesnt want a boyfriend',\n",
      "  'how much'],\n",
      " ['i cant take a girl like that out on twenty bucks', 'fine thirty'],\n",
      " ['take it or leave it this isnt a negotiation',\n",
      "  'fifty and youve got your man'],\n",
      " ['when i shell out fifty i expect results',\n",
      "  'im on it',\n",
      "  'watching the bitch trash my car doesnt count as a date',\n",
      "  'i got her under control she just acts crazed in public to keep up the '\n",
      "  'image'],\n",
      " ['i just upped my price',\n",
      "  'what',\n",
      "  'a hundred bucks a date',\n",
      "  'forget it',\n",
      "  'forget her sister then'],\n",
      " ['its about time', 'a deals a deal'],\n",
      " ['howd you do it', 'do what', 'get her to act like a human'],\n",
      " ['i dont know dorsey the limothe flowers another hundred for the tux',\n",
      "  'enough with the barbie n ken shit i know']]\n"
     ]
    }
   ],
   "source": [
    "conversations_with_lines = []\n",
    "for conversation in conversations:\n",
    "    conversations_with_lines.append([lines[key] for key in conversation])\n",
    "    \n",
    "pprint(conversations_with_lines[100:110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair those things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again',\n",
      "       'well i thought wed start with pronunciation if thats okay with you'],\n",
      "      dtype='<U2857')\n",
      "array(['well i thought wed start with pronunciation if thats okay with you',\n",
      "       'not the hacking and gagging and spitting part please'],\n",
      "      dtype='<U2857')\n",
      "array(['not the hacking and gagging and spitting part please',\n",
      "       'okay then how bout we try out some french cuisine saturday night'],\n",
      "      dtype='<U2857')\n",
      "array(['youre asking me out thats so cute whats your name again',\n",
      "       'forget it'], dtype='<U2857')\n",
      "array(['no no its my fault we didnt have a proper introduction',\n",
      "       'cameron'], dtype='<U2857')\n",
      "array(['cameron',\n",
      "       'the thing is cameron im at the mercy of a particularly hideous breed of loser my sister i cant date until she does'],\n",
      "      dtype='<U2857')\n",
      "array(['the thing is cameron im at the mercy of a particularly hideous breed of loser my sister i cant date until she does',\n",
      "       'seems like she could get a date easy enough'], dtype='<U2857')\n",
      "array(['why',\n",
      "       'unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something'],\n",
      "      dtype='<U2857')\n",
      "array(['unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
      "       'thats a shame'], dtype='<U2857')\n",
      "array(['gosh if only we could find kat a boyfriend',\n",
      "       'let me see what i can do'], dtype='<U2857')\n"
     ]
    }
   ],
   "source": [
    "def pair_it(my_list):\n",
    "    pairs = []\n",
    "    for i in range(len(my_list) -1):\n",
    "        pairs.append([my_list[i], my_list[i + 1]])\n",
    "    return pairs\n",
    "\n",
    "paired_conversations_agg = [\n",
    "    pair_it(conversation) for conversation in conversations_with_lines\n",
    "]\n",
    "conversations_pairs = np.array([item for sublist in paired_conversations_agg for item in sublist])\n",
    "for i in range(10):\n",
    "    pprint(conversations_pairs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest conversation: \n",
      "['what'\n",
      " 'then lets begin with the story itself its a story of the grail mythand although there are several variations my favorite begins with the fisher king as a young boy who had to spend a night alone in the forest to prove his courage and during that night he is visited by a sacred vision out of the fire appears the holy grail gods highest symbol of divine grace and a voice says to the boy you shall be the guardian of the grail that it may heal the hearts of menbut the boy was overcome innocent and foolish he was blinded by greater visions a life ahead filled with beauty and glory hope and powertears filled his eyes as he sensed his own invincibility a boys tears of naive wonder and inspiration and in this state ofradical amazementhe felt for a brief moment not like a boy but like god and so he reached into the fire to take the grail and the grail vanished and the boy hands were left caught in the flamesleaving him wounded and ashamed at what his recklessness had lost him when he became king he was determined to reclaim his destiny and find the grail but with each year that passed with each campaign he fought the grail remained lost and this wound he suffered in the fire grew worse he became a bitter man life for him lost its reason with each disappointment with each betrayal with each loss this wound would grow soon the land began to spoil from neglect and his people starveduntil finally the king lost all faith in gods existance and in mans valuehe lost his ability to love or be loved and he was so sick with experience that he started to die as the years went on his bravest knights would search for the grail that would heal their king and make them the most respected and valued men in the land but to no avail pretty soon finding the grail became a ruthless struggle between ambitious men vying for the kings power which only confirmed the kings worst suspicions of man causing his wound to grow his only hope he thought was death then one day a fool was brought in to the king to cheer him he was a simpleminded man not particularly skilledor admired he tells the king some jokessing him some songs but the king feels even worsefinally the fool says what is it that hurts you so much how can i helpand the king says i need a sip of water to cool my throatso the fool takes a cup from the bedstand fills it with water and hands it to the kingsuddenly the king feels a lot better and when he looks to his hands he sees that it was the holy grail the fool handed himan ordinary cup that had been beside his bed all alongand the king asks how can this behow could you find what all my knights and wisest men could not find and the fool answers i dont know i only knew you were thirsty and for the first time since he was a boy the king felt more than a man not because he was touched by gods glorybut rather by the compassion of a fool']\n",
      "\n",
      "longest conversation has 553 words.\n",
      "filetered 169323 conversations\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest conversation in reduce dataset: \n",
      "['thats because its such a nice one' 'forget french']\n",
      "\n",
      "longest conversation in reduce dataset has 9 words.\n"
     ]
    }
   ],
   "source": [
    "hist, edges  = np.histogram([len(question.split(' ')) + len(answer.split(' ')) for question, answer in conversations_pairs], density=True, bins=100)\n",
    "center = (edges[:-1] + edges[1:]) / 2\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.xlabel('all conversations', fontsize=14)\n",
    "plt.bar(center, hist, align='center', width=(edges[1] - edges[0]) * .8)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "longest_converastion = conversations_pairs[np.array([len(question.split(' ')) + len(answer.split(' ')) for question, answer in conversations_pairs]).argmax()]\n",
    "print(\"longest conversation: \\n{}\\n\".format(longest_converastion))\n",
    "print(\"longest conversation has {} words.\".format(len(longest_converastion[0].split(' ')) + len(longest_converastion[1].split(' '))))\n",
    "max_conversation_lenght = 10  # maximum alowed converastion lenght in words\n",
    "clensed_conversations = np.array([conversation_pair for conversation_pair in conversations_pairs  if (len(conversation_pair[0].split(' ')) + len(conversation_pair[1].split(' '))) < max_conversation_lenght])\n",
    "print(\"filetered {} conversations\\n\".format(len(conversations_pairs) - len(clensed_conversations)))\n",
    "\n",
    "hist, edges  = np.histogram([len(question.split(' ')) + len(answer.split(' ')) for question, answer in clensed_conversations], density=True, bins=100)\n",
    "center = (edges[:-1] + edges[1:]) / 2\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.bar(center, hist, align='center', width=(edges[1] - edges[0]) * .8)\n",
    "plt.xlabel('reduced conversations', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "longest_converastion = clensed_conversations[np.array([len(question.split(' ')) + len(answer.split(' ')) for question, answer in clensed_conversations]).argmax()]\n",
    "print(\"longest conversation in reduce dataset: \\n{}\\n\".format(longest_converastion))\n",
    "print(\"longest conversation in reduce dataset has {} words.\".format(len(longest_converastion[0].split(' ')) + len(longest_converastion[1].split(' '))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shity magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first word: you, last word: artillery\n",
      "max sentence lenght: 8 words\n",
      "vocab_size: 17654 words\n",
      "trainX steps 41834\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "trainY steps 41834\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "testX steps 10459\n",
      "0\n",
      "10000\n",
      "testY steps 10459\n",
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clensed_conversations.reshape(-1))\n",
    "vocabulary = np.fromiter(tokenizer.word_index.keys(), dtype=\"<U34\")\n",
    "\n",
    "# vocabulary = set()\n",
    "all_lines = clensed_conversations.reshape(-1)\n",
    "# for line in all_lines:\n",
    "#     for word in line.split():\n",
    "#         if word not in vocabulary:\n",
    "#             vocabulary.add(word)\n",
    "# vocabulary = np.array(sorted(vocabulary))\n",
    "\n",
    "max_sentence_lenght = max(len(line.split()) for line in all_lines)\n",
    "print(\"first word: {}, last word: {}\".format(vocabulary[0], vocabulary[-1]))\n",
    "print('max sentence lenght: {} words'.format(max_sentence_lenght))\n",
    "print('vocab_size: {} words'.format(len(vocabulary)))\n",
    "\n",
    "split_index = int(len(clensed_conversations) * .8)\n",
    "\n",
    "trainX = np.zeros((len(clensed_conversations[:split_index]), max_sentence_lenght), dtype='uint16')\n",
    "trainY = np.zeros((len(clensed_conversations[:split_index]), max_sentence_lenght, len(vocabulary)), dtype='uint8')\n",
    "testX = np.zeros((len(clensed_conversations[split_index:]), max_sentence_lenght), dtype='uint16')\n",
    "testY = np.zeros((len(clensed_conversations[split_index:]), max_sentence_lenght, len(vocabulary)), dtype='uint8')\n",
    "\n",
    "print(\"trainX steps {}\".format(len(trainX)))\n",
    "for i, (sentence) in enumerate(clensed_conversations[:split_index, 0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    for j, (word) in enumerate(sentence.split()):\n",
    "        trainX[i, j] = np.where(vocabulary == word)[0][0]\n",
    "        \n",
    "print(\"trainY steps {}\".format(len(trainY)))\n",
    "for i, (sentence) in enumerate(clensed_conversations[:split_index, 1]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    for j, (word) in enumerate(sentence.split()):\n",
    "        index_of_word = np.where(vocabulary == word)[0][0]\n",
    "        trainY[i, j, index_of_word] = 1\n",
    "        \n",
    "print(\"testX steps {}\".format(len(testX)))\n",
    "for i, (sentence) in enumerate(clensed_conversations[split_index:, 0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    for j, (word) in enumerate(sentence.split()):\n",
    "        testX[i, j] = np.where(vocabulary == word)[0][0]\n",
    "        \n",
    "print(\"testY steps {}\".format(len(testY)))\n",
    "for i, (sentence) in enumerate(clensed_conversations[split_index:, 1]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    for j, (word) in enumerate(sentence.split()):\n",
    "        index_of_word = np.where(vocabulary == word)[0][0]\n",
    "        testY[i, j, index_of_word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 256)            4519424   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 17654)          4537078   \n",
      "=================================================================\n",
      "Total params: 10,107,126\n",
      "Trainable params: 10,107,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "n_units=256\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocabulary), n_units, input_length=max_sentence_lenght, mask_zero=True))\n",
    "model.add(LSTM(n_units))  # CuDNNLSTM\n",
    "model.add(RepeatVector(max_sentence_lenght))\n",
    "model.add(LSTM(n_units, return_sequences=True))  # CuDNNLSTM\n",
    "model.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41834 samples, validate on 10459 samples\n",
      "Epoch 1/20\n",
      "41834/41834 [==============================] - 368s 9ms/step - loss: 2.6781 - val_loss: 2.6546\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.67812, saving model to mount-this/model.h5\n",
      "Epoch 2/20\n",
      "41834/41834 [==============================] - 365s 9ms/step - loss: 2.4917 - val_loss: 2.6799\n",
      "\n",
      "Epoch 00002: loss improved from 2.67812 to 2.49168, saving model to mount-this/model.h5\n",
      "Epoch 3/20\n",
      "41834/41834 [==============================] - 359s 9ms/step - loss: 2.4536 - val_loss: 2.6920\n",
      "\n",
      "Epoch 00003: loss improved from 2.49168 to 2.45365, saving model to mount-this/model.h5\n",
      "Epoch 4/20\n",
      "41834/41834 [==============================] - 361s 9ms/step - loss: 2.4188 - val_loss: 2.7041\n",
      "\n",
      "Epoch 00004: loss improved from 2.45365 to 2.41884, saving model to mount-this/model.h5\n",
      "Epoch 5/20\n",
      "41834/41834 [==============================] - 362s 9ms/step - loss: 2.3813 - val_loss: 2.7191\n",
      "\n",
      "Epoch 00005: loss improved from 2.41884 to 2.38132, saving model to mount-this/model.h5\n",
      "Epoch 6/20\n",
      "41834/41834 [==============================] - 357s 9ms/step - loss: 2.3416 - val_loss: 2.7337\n",
      "\n",
      "Epoch 00006: loss improved from 2.38132 to 2.34162, saving model to mount-this/model.h5\n",
      "Epoch 7/20\n",
      "41834/41834 [==============================] - 360s 9ms/step - loss: 2.3011 - val_loss: 2.7534\n",
      "\n",
      "Epoch 00007: loss improved from 2.34162 to 2.30105, saving model to mount-this/model.h5\n",
      "Epoch 8/20\n",
      "41834/41834 [==============================] - 361s 9ms/step - loss: 2.2601 - val_loss: 2.7707\n",
      "\n",
      "Epoch 00008: loss improved from 2.30105 to 2.26013, saving model to mount-this/model.h5\n",
      "Epoch 9/20\n",
      "41834/41834 [==============================] - 360s 9ms/step - loss: 2.2165 - val_loss: 2.7890\n",
      "\n",
      "Epoch 00009: loss improved from 2.26013 to 2.21647, saving model to mount-this/model.h5\n",
      "Epoch 10/20\n",
      "41834/41834 [==============================] - 359s 9ms/step - loss: 2.1705 - val_loss: 2.8125\n",
      "\n",
      "Epoch 00010: loss improved from 2.21647 to 2.17050, saving model to mount-this/model.h5\n",
      "Epoch 11/20\n",
      "41834/41834 [==============================] - 359s 9ms/step - loss: 2.1250 - val_loss: 2.8397\n",
      "\n",
      "Epoch 00011: loss improved from 2.17050 to 2.12497, saving model to mount-this/model.h5\n",
      "Epoch 12/20\n",
      "41834/41834 [==============================] - 360s 9ms/step - loss: 2.0778 - val_loss: 2.8631\n",
      "\n",
      "Epoch 00012: loss improved from 2.12497 to 2.07781, saving model to mount-this/model.h5\n",
      "Epoch 13/20\n",
      "41834/41834 [==============================] - 384s 9ms/step - loss: 2.0307 - val_loss: 2.8791\n",
      "\n",
      "Epoch 00013: loss improved from 2.07781 to 2.03065, saving model to mount-this/model.h5\n",
      "Epoch 14/20\n",
      "41834/41834 [==============================] - 388s 9ms/step - loss: 1.9818 - val_loss: 2.8974\n",
      "\n",
      "Epoch 00014: loss improved from 2.03065 to 1.98180, saving model to mount-this/model.h5\n",
      "Epoch 15/20\n",
      "41834/41834 [==============================] - 377s 9ms/step - loss: 1.9337 - val_loss: 2.9250\n",
      "\n",
      "Epoch 00015: loss improved from 1.98180 to 1.93366, saving model to mount-this/model.h5\n",
      "Epoch 16/20\n",
      "41834/41834 [==============================] - 365s 9ms/step - loss: 1.8858 - val_loss: 2.9434\n",
      "\n",
      "Epoch 00016: loss improved from 1.93366 to 1.88577, saving model to mount-this/model.h5\n",
      "Epoch 17/20\n",
      "41834/41834 [==============================] - 361s 9ms/step - loss: 1.8383 - val_loss: 2.9616\n",
      "\n",
      "Epoch 00017: loss improved from 1.88577 to 1.83833, saving model to mount-this/model.h5\n",
      "Epoch 18/20\n",
      "41834/41834 [==============================] - 363s 9ms/step - loss: 1.7937 - val_loss: 2.9868\n",
      "\n",
      "Epoch 00018: loss improved from 1.83833 to 1.79369, saving model to mount-this/model.h5\n",
      "Epoch 19/20\n",
      "41834/41834 [==============================] - 357s 9ms/step - loss: 1.7499 - val_loss: 3.0041\n",
      "\n",
      "Epoch 00019: loss improved from 1.79369 to 1.74994, saving model to mount-this/model.h5\n",
      "Epoch 20/20\n",
      "41834/41834 [==============================] - 359s 9ms/step - loss: 1.7071 - val_loss: 3.0204\n",
      "\n",
      "Epoch 00020: loss improved from 1.74994 to 1.70711, saving model to mount-this/model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129611f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "filename = 'mount-this/model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"mount-this/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_infer = 'how are you'\n",
    "source = np.zeros(max_sentence_lenght)\n",
    "\n",
    "for i in range(len(to_infer.split())):\n",
    "    source[i] = np.where(vocabulary == to_infer.split()[i])[0][0]\n",
    "source = source.reshape((1, source.shape[0]))\n",
    "res = model.predict(source)\n",
    "sentence = \"\".join([vocabulary[np.argmax(word_indexes)] for word_indexes in res[0] if np.max(word_indexes) > .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fine'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
